{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de748ceb-42b7-4f11-ac6b-ad160c680099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import copy\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import warnings\n",
    "import timeit\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import optim\n",
    "from scipy.special import expit\n",
    "from skimage import io, transform, measure\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "from config import *\n",
    "from util import *\n",
    "from models import *\n",
    "sns.set()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "rc = {\"figure.figsize\" : (9, 7),\n",
    "      \"axes.spines.left\" : False,\n",
    "      \"axes.spines.right\" : False, \n",
    "      \"axes.spines.bottom\" : False,\n",
    "      \"axes.spines.top\" : False,\n",
    "      \"xtick.bottom\" : True,\n",
    "      \"xtick.labelbottom\" : False,\n",
    "      \"ytick.labelleft\" : False,\n",
    "      \"ytick.left\" : True,\n",
    "      \"axes.grid\" : False}\n",
    "plt.rcParams.update(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c6752b-6827-42b6-9f83-340b6784a6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c410c2-f901-4492-90b8-4b6867233715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b178657-d36b-46c5-a09e-28a4ca686d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda._lazy_init()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "metadata = pd.read_csv(metadata_file)\n",
    "\n",
    "test_set_group = '2'\n",
    "test_set = pd.read_csv(\"../data/test_set\"+test_set_group+\".csv\")\n",
    "\n",
    "model = CharacteristicsClassifier()\n",
    "model.load_state_dict(torch.load(\"models/combined_model.pth\"))\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31921af9-8327-4677-b7e2-21c43522edf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8e6bb-9909-48c2-8343-dc6220f29535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2413d-d7e9-4f2c-ba1c-6b9b97485de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916a8fed-528e-414d-b577-c322b4c2a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_batch():\n",
    "    image_batch = []\n",
    "    for image_id in test_set.image_id.values:\n",
    "        if \"ISIC\" in image_id:\n",
    "            extension = '.jpg'\n",
    "            image = io.imread(os.path.join(img_dir, image_id + extension))\n",
    "            image = model.test_transform(image=image)['image']\n",
    "        else:\n",
    "            extension = '.png'\n",
    "            image = io.imread(os.path.join(img_dir, image_id + extension), as_gray=False)[:,:,:3]\n",
    "            image = model.test_transform(image=image)['image']\n",
    "        image_batch.append(image)\n",
    "\n",
    "    image_batch = torch.stack(image_batch).to(device)\n",
    "    return image_batch\n",
    "\n",
    "image_batch = get_image_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a2d88-dbae-40f2-88a1-159acb4f2c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb338a5-7404-45e5-a784-e66660030d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b6a7c-49af-430b-a969-ec8975d86f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bf59c1-c7c6-42a7-a02f-958f95b60b7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(attributions, size\u001b[38;5;241m=\u001b[39m(image_size, image_size), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m diagnosis_output, characteristics_output, attributions\n\u001b[0;32m---> 11\u001b[0m diagnosis_output, characteristics_output, attributions \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(diagnosis_output \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdx_threshold, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     13\u001b[0m char_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(characteristics_output \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mchar_threshold, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(x):\n\u001b[0;32m----> 2\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     diagnosis_output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdiagnosis_head(output)\n\u001b[1;32m      4\u001b[0m     characteristics_output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcharacteristics_head(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/eye_tracking/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/eye_tracking/lib/python3.9/site-packages/torchvision/models/resnet.py:249\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/eye_tracking/lib/python3.9/site-packages/torchvision/models/resnet.py:232\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    234\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/eye_tracking/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/eye_tracking/lib/python3.9/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/eye_tracking/lib/python3.9/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "def forward(x):\n",
    "    output = model.base_model(x)\n",
    "    diagnosis_output = model.diagnosis_head(output)\n",
    "    characteristics_output = model.characteristics_head(output)\n",
    "    \n",
    "    attributions = torch.cat([model.attribute(characteristics_output, class_idx) for class_idx in range(model.num_classes)], dim=1)\n",
    "    attributions = F.interpolate(attributions, size=(image_size, image_size), mode='bilinear')\n",
    "    return diagnosis_output, characteristics_output, attributions\n",
    "\n",
    "\n",
    "diagnosis_output, characteristics_output, attributions = forward(image_batch)\n",
    "predictions = torch.where(diagnosis_output >= model.dx_threshold, 1, 0).cpu().numpy().flatten()\n",
    "char_predictions = torch.where(characteristics_output >= model.char_threshold, 1, 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fdf37b-f1e1-4944-8bfb-63098e047ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169e2ed-d8a8-4102-8a65-245fdfdb5abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e72a85-d73f-4d28-bb39-e6109bcc308c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab348ed7-b81b-4e29-bad4-3f8ec496566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = []\n",
    "for i in range(len(test_set)):\n",
    "    if test_set.iloc[i].prediction == 1:\n",
    "        idx = char_predictions[i][0:len(mel_class_labels)]\n",
    "        \n",
    "        explanation = mel_class_labels[characteristics_output[i][0:len(mel_class_labels)].argmax().item()]\n",
    "        explanations.append(explanation)\n",
    "    else:\n",
    "        idx = char_predictions[i][len(mel_class_labels):]\n",
    "        \n",
    "        explanation = nev_class_labels[characteristics_output[i][len(mel_class_labels):].argmax().item()]\n",
    "        explanations.append(explanation)\n",
    "        \n",
    "test_set['explanation'] = explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15968f54-45d8-42b3-a0a6-02b3a437ad6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b8f269-6dd1-4a18-9ff6-3abdb6f948b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84a90a44-76df-4e4e-97e6-c073c222dd65",
   "metadata": {},
   "source": [
    "## XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda3dc2-d75b-4cac-929a-6ecd5a93bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    0: 'Nevus',\n",
    "    1: 'Melanoma',\n",
    "    'TRBL': 'Thick reticular or branched lines',\n",
    "    'BDG': 'Black dots and globules',\n",
    "    'GP': 'Grey patterns',\n",
    "    'WLSA': 'White lines or white structureless area',\n",
    "    'PRL': 'Pseudopods or radial lines in the periphery of the lesion',\n",
    "    'PV': 'Polymorphous vessels',\n",
    "    'SPC': 'Symmetric combination of patterns or colors',\n",
    "    'APC': 'Asymmetric combination of multiple patterns and;or colours \\nin the absence of other melanoma criteria',\n",
    "    'OPC': 'Only one pattern and;or color',\n",
    "    'MVP': 'Monomorphic vascular pattern'\n",
    "}\n",
    "\n",
    "for idx, row in test_set.iterrows():\n",
    "    #print('image_id:', row.image_id)\n",
    "    #print('prediction:', row.prediction)\n",
    "    #print('explanation:', row.explanation)\n",
    "    try:\n",
    "        img = io.imread(os.path.join(img_dir, row.image_id+'.png'))\n",
    "    except:\n",
    "        img = io.imread(os.path.join(img_dir, row.image_id+'.jpg'))\n",
    "    img = transform.resize(img, (450, 600))\n",
    "    \n",
    "    attr = attributions[idx][char_class_labels.index(row.explanation)].cpu().detach().numpy()\n",
    "    attr = transform.resize(attr, (450, 600))\n",
    "        \n",
    "    attr_non_zero = attr[attr>0.]\n",
    "    if len(attr_non_zero) == 0:\n",
    "        perc = 0\n",
    "    else:\n",
    "        perc = (np.percentile(attr_non_zero, 85))\n",
    "    attr = (attr >= perc)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18, 8))\n",
    "    contours = measure.find_contours(attr)\n",
    "    for contour in contours:\n",
    "        ax[1].plot(contour[:, 1], contour[:, 0], linewidth=0.9, color='white')\n",
    "    \n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(img)\n",
    "    text = f\"The AI predicted {mappings[row.prediction]} because of\"\n",
    "    ax[0].text(0.7, -0.05, text, fontsize=15, ha='center', va='center', weight='bold', transform=ax[0].transAxes)\n",
    "    text = f\" {mappings[row.explanation]}\"\n",
    "    ax[1].text(0.3, -0.05, text, fontsize=15, ha='center', va='center', weight='bold', transform=ax[1].transAxes)\n",
    "    ax[1].axis('off')\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(\"figures\", row.image_id+'.jpg'), dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(\"../figures_xai\", \"group\"+test_set_group, row.image_id+'.jpg'), dpi=300, bbox_inches='tight')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4121c-bfe7-4c5f-9144-0169cdee4d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a365d9c-48fd-4b41-8224-1066fedcd163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e2d25-7916-4a21-becd-c8d9c9c8814b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4fefa-0078-4742-86b2-002c7fe00194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d52a5c-56db-4e45-9c68-2dd235237975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77fb84-c291-4210-9e55-e694e104d542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad704a4-076d-4011-b2e0-36e41968a9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf7164-3038-4e46-9924-70adb2bafd58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96db9de-4289-4287-b1d2-e62c01738127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2587388-dd24-412e-b8f9-a5afb7ca5e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55d9ef-3f08-41a5-97df-6e569edb494e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b21f09-7bc5-4f13-93ef-b991ef96a216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9506df1f-3fcf-4b58-81c0-e531dbb86495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1be281-8720-4912-b9d8-12358254daf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54243b6e-c79b-4f47-be43-e91ab6c3b921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
